{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f3b77dd",
   "metadata": {
    "papermill": {
     "duration": 0.003026,
     "end_time": "2025-12-15T10:34:30.510225",
     "exception": false,
     "start_time": "2025-12-15T10:34:30.507199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961ecc58",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-15T10:34:30.515366Z",
     "iopub.status.busy": "2025-12-15T10:34:30.515105Z",
     "iopub.status.idle": "2025-12-15T10:34:41.581117Z",
     "shell.execute_reply": "2025-12-15T10:34:41.580484Z"
    },
    "papermill": {
     "duration": 11.070038,
     "end_time": "2025-12-15T10:34:41.582457",
     "exception": false,
     "start_time": "2025-12-15T10:34:30.512419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58d175",
   "metadata": {
    "papermill": {
     "duration": 0.002041,
     "end_time": "2025-12-15T10:34:41.586733",
     "exception": false,
     "start_time": "2025-12-15T10:34:41.584692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Enable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da338255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:34:41.591648Z",
     "iopub.status.busy": "2025-12-15T10:34:41.591327Z",
     "iopub.status.idle": "2025-12-15T10:34:41.674135Z",
     "shell.execute_reply": "2025-12-15T10:34:41.673368Z"
    },
    "papermill": {
     "duration": 0.086503,
     "end_time": "2025-12-15T10:34:41.675192",
     "exception": false,
     "start_time": "2025-12-15T10:34:41.588689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416ef0d",
   "metadata": {},
   "source": [
    "# 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 官方参数\n",
    "hyper_params_default = {\n",
    "    \"learning_rate\": 0.001,       # 学习率\n",
    "    \"batch_size\": 64,             # 批次大小\n",
    "    \"epochs\": 15,                # 训练轮数\n",
    "    \"optimizer\": \"Adam\",          # 优化器\n",
    "    \"loss_function\": \"CrossEntropyLoss\",  # 损失函数\n",
    "    \"dropout_rate\": 0.5,         # dropout率\n",
    "    \"weight_decay\": 0.01,       # 权重衰减\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b2fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义本次训练的超参数\n",
    "hyper_params = {\n",
    "    \"learning_rate\": 0.00001,       # 学习率\n",
    "    \"batch_size\": 128,             # 批次大小\n",
    "    \"epochs\": 50,                # 训练轮数\n",
    "    \"optimizer\": \"Adam\",          # 优化器\n",
    "    \"loss_function\": \"CrossEntropyLoss\",  # 损失函数\n",
    "    \"dropout_rate\": 0.5,         # dropout率\n",
    "    \"weight_decay\": 0.0001,       # 权重衰减\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba8d548",
   "metadata": {
    "papermill": {
     "duration": 0.002032,
     "end_time": "2025-12-15T10:34:41.679406",
     "exception": false,
     "start_time": "2025-12-15T10:34:41.677374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c14d2d48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:34:41.684394Z",
     "iopub.status.busy": "2025-12-15T10:34:41.684181Z",
     "iopub.status.idle": "2025-12-15T10:34:41.690326Z",
     "shell.execute_reply": "2025-12-15T10:34:41.689745Z"
    },
    "papermill": {
     "duration": 0.009841,
     "end_time": "2025-12-15T10:34:41.691329",
     "exception": false,
     "start_time": "2025-12-15T10:34:41.681488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(hyper_params[\"dropout_rate\"]),\n",
    "            nn.Linear(4*4*512, 38)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78867d0",
   "metadata": {
    "papermill": {
     "duration": 0.001906,
     "end_time": "2025-12-15T10:34:41.695210",
     "exception": false,
     "start_time": "2025-12-15T10:34:41.693304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72908a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:34:41.700062Z",
     "iopub.status.busy": "2025-12-15T10:34:41.699865Z",
     "iopub.status.idle": "2025-12-15T10:35:30.173943Z",
     "shell.execute_reply": "2025-12-15T10:35:30.173104Z"
    },
    "papermill": {
     "duration": 48.478228,
     "end_time": "2025-12-15T10:35:30.175354",
     "exception": false,
     "start_time": "2025-12-15T10:34:41.697126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 归一化后像素值 = (原始像素值（0-1 范围） - 均值) / 标准差\n",
    "t = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "path = \"New Plant Diseases Dataset\"\n",
    "\n",
    "train = datasets.ImageFolder(path + \"/train\", transform=t)\n",
    "test = datasets.ImageFolder(path + \"/valid\", transform=t)\n",
    "print(f'train.class_to_idx: {train.class_to_idx}')\n",
    "\n",
    "\n",
    "train = DataLoader(train, batch_size=hyper_params[\"batch_size\"], shuffle=True, num_workers=4, pin_memory=True)\n",
    "test = DataLoader(test, batch_size=hyper_params[\"batch_size\"], shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777a9f78",
   "metadata": {
    "papermill": {
     "duration": 0.002051,
     "end_time": "2025-12-15T10:35:30.179728",
     "exception": false,
     "start_time": "2025-12-15T10:35:30.177677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331bc515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:35:30.184838Z",
     "iopub.status.busy": "2025-12-15T10:35:30.184563Z",
     "iopub.status.idle": "2025-12-15T10:35:30.382423Z",
     "shell.execute_reply": "2025-12-15T10:35:30.381839Z"
    },
    "papermill": {
     "duration": 0.202048,
     "end_time": "2025-12-15T10:35:30.383844",
     "exception": false,
     "start_time": "2025-12-15T10:35:30.181796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = cnn()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=hyper_params[\"learning_rate\"], weight_decay=hyper_params[\"weight_decay\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a709a29",
   "metadata": {
    "papermill": {
     "duration": 0.002205,
     "end_time": "2025-12-15T10:35:30.388422",
     "exception": false,
     "start_time": "2025-12-15T10:35:30.386217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c627c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:35:30.393498Z",
     "iopub.status.busy": "2025-12-15T10:35:30.393303Z",
     "iopub.status.idle": "2025-12-15T10:58:47.492589Z",
     "shell.execute_reply": "2025-12-15T10:58:47.491741Z"
    },
    "papermill": {
     "duration": 1397.103463,
     "end_time": "2025-12-15T10:58:47.494023",
     "exception": false,
     "start_time": "2025-12-15T10:35:30.390560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 初始化 TensorBoard\n",
    "\n",
    "writer = SummaryWriter(log_dir= f'runs/{time.strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "\n",
    "hyper_params[\"start_time\"] = time.strftime(\"%Y%m%d-%H%M%S\")  # 训练开始时间\n",
    "\n",
    "table_content = \"\"\"\n",
    "| 超参数名称 | 参数值 |\n",
    "|------------|--------|\n",
    "\"\"\"\n",
    "for param_name, param_value in hyper_params.items():\n",
    "    table_content += f\"| {param_name} | {param_value} |\\n\"\n",
    "\n",
    "# 写入TensorBoard（step设为0，代表训练开始前）\n",
    "writer.add_text(\n",
    "    tag=\"Experiment_Config/Hyperparameters\",\n",
    "    text_string=table_content,\n",
    "    global_step=0\n",
    ")\n",
    "print(\"✅ 训练开始前已记录超参数表格到TensorBoard\")\n",
    "\n",
    "epochs = hyper_params[\"epochs\"]\n",
    "global_step = 0  # 记录全局步数\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loop = tqdm(train, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    epoch_last_step_loss = 0\n",
    "    epoch_last_step_acc = 0\n",
    "    final_loss = 0\n",
    "    final_train_acc = 0\n",
    "    for features, labels in loop:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(features)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _,pred = torch.max(pred, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=(correct/total)*100)\n",
    "        writer.add_scalar('Loss/train-step', loss.item(), global_step)\n",
    "        writer.add_scalar('Accuracy/train-step', (correct/total)*100, global_step)\n",
    "        epoch_last_step_loss = loss.item()\n",
    "        epoch_last_step_acc = (correct/total)*100\n",
    "        global_step += 1\n",
    "    \n",
    "    writer.add_scalar('Loss/train-epoch', epoch_last_step_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train-epoch', epoch_last_step_acc, epoch)\n",
    "    # 测试集评估\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            preds = model(features)\n",
    "            _, preds = torch.max(preds, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        test_acc = (correct / total) * 100\n",
    "        writer.add_scalar('Accuracy/valid-epoch', test_acc, epoch)\n",
    "writer.close()\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b387e9",
   "metadata": {
    "papermill": {
     "duration": 0.980873,
     "end_time": "2025-12-15T10:58:49.546150",
     "exception": false,
     "start_time": "2025-12-15T10:58:48.565277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa44788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T10:58:51.655918Z",
     "iopub.status.busy": "2025-12-15T10:58:51.655557Z",
     "iopub.status.idle": "2025-12-15T10:59:24.328401Z",
     "shell.execute_reply": "2025-12-15T10:59:24.327594Z"
    },
    "papermill": {
     "duration": 34.685606,
     "end_time": "2025-12-15T10:59:25.283790",
     "exception": false,
     "start_time": "2025-12-15T10:58:50.598184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for features, labels in test:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        preds = model(features)\n",
    "        _, preds = torch.max(preds, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(cm, annot=False, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "accuracy = (correct/total)*100\n",
    "print(f\"Test accuracy: {accuracy}\")\n",
    "torch.save(model.state_dict(), f\"plant_disease_{int(accuracy)}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b705b08b",
   "metadata": {},
   "source": [
    "# 导出onnx模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4a3a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载预训练模型: plant_disease_98-20260103-114257.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hszql\\AppData\\Local\\Temp\\ipykernel_2344\\2461172510.py:36: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功导出ONNX模型到: onnx/plant_disease_98-20260103-114257.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 初始化模型\n",
    "model = cnn()\n",
    "model = model.to(device)\n",
    "# 加载预训练权重\n",
    "model_path = \"plant_disease_98-20260103-114257.pth\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    try:\n",
    "        # 加载模型权重\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(f\"成功加载预训练模型: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载模型失败: {e}\")\n",
    "        # 尝试另一种加载方式\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
    "            print(f\"使用strict=False成功加载模型: {model_path}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"使用strict=False也加载失败: {e2}\")\n",
    "            exit(1)\n",
    "else:\n",
    "    print(f\"模型文件不存在: {model_path}\")\n",
    "    exit(1)\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 创建一个示例输入张量（与模型期望的输入形状一致）\n",
    "# 输入形状: [batch_size, channels, height, width]\n",
    "# 这里使用batch_size=1, channels=3, height=256, width=256\n",
    "dummy_input = torch.randn(1, 3, 256, 256).to(device)\n",
    "\n",
    "# 导出为ONNX格式\n",
    "onnx_path = f\"onnx/{model_path.split('.pth')[0]}.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,  # 导出训练好的权重\n",
    "    opset_version=18,    # ONNX操作集版本\n",
    "    do_constant_folding=True,  # 是否执行常量折叠优化\n",
    "    input_names=['input'],  # 输入张量的名称\n",
    "    output_names=['output'],  # 输出张量的名称\n",
    "    # 新版本推荐的动态形状设置方式\n",
    "    dynamic_axes ={\n",
    "        'input': {0: 'batch_size'},  # 允许batch_size动态变化\n",
    "        'output': {0: 'batch_size'}\n",
    "    },\n",
    "    # 禁用dynamo（避免自动转换带来的问题）\n",
    "    dynamo=False,\n",
    "    # 确保导出为单个文件\n",
    "    keep_initializers_as_inputs=False\n",
    ")\n",
    "\n",
    "print(f\"成功导出ONNX模型到: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fb9f638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX模型验证通过\n"
     ]
    }
   ],
   "source": [
    "# 验证ONNX模型\n",
    "import onnx\n",
    "try:\n",
    "    # 加载ONNX模型\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    # 检查模型结构是否正确\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    print(\"ONNX模型验证通过\")\n",
    "except Exception as e:\n",
    "    print(f\"ONNX模型验证失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79fd468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test.class_to_idx)\n",
    "# print(test.num_workers)\n",
    "# tensorboard --logdir=runs/train_exp --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20d182",
   "metadata": {},
   "source": [
    "命令模式下：\n",
    "\n",
    "Shift➕回车 运行当前代码块，并跳到下一个代码块\n",
    "\n",
    "Ctrl➕回车，只会运行当前代码块\n",
    "\n",
    "Alt➕回车，运行当前代码块，并向下新建一个代码块\n",
    "\n",
    "按b，向下新建一个代码块\n",
    "\n",
    "按a，向上新建一个代码块\n",
    "\n",
    "按c，复制当前代码块（单元格）\n",
    "\n",
    "按x，剪切掉当前代码块\n",
    "\n",
    "按v，粘贴到当前代码块；按shift➕v，粘贴到上一个代码块\n",
    "\n",
    "按z，撤回操作\n",
    "\n",
    "对于多行代码，在代码块命令模式下，按L，可以对代码标行数\n",
    "\n",
    "按dd（两次），删除代码块\n",
    "\n",
    "按h键，可以调出markdown的快捷键介绍表格"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 78313,
     "sourceId": 182633,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "new_plant_diseases",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1501.075743,
   "end_time": "2025-12-15T10:59:28.174896",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-15T10:34:27.099153",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
